{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from PyDictionary import PyDictionary\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from gingerit.gingerit import GingerIt\n",
    "from random import randint\n",
    "from difflib import SequenceMatcher\n",
    "from random import sample\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    ''' Function that takes a tow questions and returns similarity between them\n",
    "    takes one argument :\n",
    "    a - frist question\n",
    "    b - second question'''\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords (qlist):\n",
    "    ''' Function that takes a list of questions and returns unique words list without stop words\n",
    "    takes one argument :\n",
    "    qlist - list of questions'''\n",
    "    \n",
    "    # tokenizer splits tokens \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    # initiate empty list to fill it in the for loop  \n",
    "    qlist2=[]\n",
    "    \n",
    "    # raverse for all questions\n",
    "    for q in qlist:\n",
    "        # append all words in the question in qlist2\n",
    "        qlist2.append(tokenizer.tokenize(q))\n",
    "    print(qlist2)\n",
    "\n",
    "    # initiate empty list to fill it in the for loop \n",
    "    words=[]\n",
    "    \n",
    "    # Remove stop words from qlist2\n",
    "    for ww in qlist2:\n",
    "        for w in ww:\n",
    "            if w not in stopwords.words('english'):\n",
    "                if w.isupper() == False:\n",
    "                    words.append(w)\n",
    "                    \n",
    "    # return all words in all questions without stop words and repetation  \n",
    "    return unique(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "    ''' Function that takes list of words and returns unique words list\n",
    "    takes one argument :\n",
    "    list1 - list of words'''\n",
    "    \n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    for i in range(len(unique_list)):\n",
    "        unique_list[i] = unique_list[i].lower()\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSynynoms (unique_):\n",
    "    ''' Function that takes unique words a list of lists that returns a list of all possible synynoms\n",
    "    takes one argument :\n",
    "    unique_ - list of orginal words'''\n",
    "    \n",
    "    # intilize three lists \n",
    "    syns = []\n",
    "    allSyn = []\n",
    "    notFound = []\n",
    "    \n",
    "    # traverse for all words in unique_\n",
    "    for word in unique_:\n",
    "        synset = wordnet.synsets(word)\n",
    "        try:\n",
    "            syns = []\n",
    "\n",
    "            # range is the length of all possible synonyms for the word include the original word\n",
    "            for i in range(len(synset[0].lemmas())):\n",
    "                # we do not want to include the original word \n",
    "                if word != synset[0].lemmas()[i].name():\n",
    "                    # add the synonym\n",
    "                    syns.append(synset[0].lemmas()[i].name())\n",
    "        except:\n",
    "            allSyn.append(syns)\n",
    "            notFound=[]\n",
    "            continue\n",
    "        # add the synonym in the list of all synynoms\n",
    "        allSyn.append(syns)\n",
    "    return allSyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calssifySynynoms(unique_, allSyn):\n",
    "    '''Function that takes a list of lists of synynoms\n",
    "    and a list of words and then classify it as\n",
    "    (noun, verb, adverb, adjective)\n",
    "    takes two argument :\n",
    "    unique_ - list of orginal words\n",
    "    allSyn - a list of all possible synynoms'''\n",
    "    \n",
    "    # initiate empty list to fill it with noun synynoms, adj synynoms, verb synynoms and adver synynoms\n",
    "    dictionary=PyDictionary()\n",
    "    nounList = []\n",
    "    adjList = []\n",
    "    verbList = []\n",
    "    adverbList = []\n",
    "\n",
    "    for lis in allSyn:\n",
    "        nouns = []\n",
    "        adjs = []\n",
    "        verbs = []\n",
    "        adverbs = []\n",
    "        for syn in lis:\n",
    "            try:\n",
    "                keys = dictionary.meaning(syn).keys()\n",
    "            except:\n",
    "                continue\n",
    "            if 'Noun' in keys:\n",
    "                nouns.append(syn)\n",
    "            if 'Verb' in keys:\n",
    "                verbs.append(syn)\n",
    "            if 'Adjective' in keys:\n",
    "                adjs.append(syn)\n",
    "            if 'Adverb' in keys:\n",
    "                adverbs.append(syn)\n",
    "\n",
    "        if len(nouns) == 0:\n",
    "            nouns.append('N/A')\n",
    "        if len(adjs) == 0:\n",
    "            adjs.append('N/A')\n",
    "        if len(verbs) == 0:\n",
    "            verbs.append('N/A')\n",
    "        if len(adverbs) == 0:\n",
    "            adverbs.append('N/A')\n",
    "\n",
    "        nounList.append(nouns)\n",
    "        adjList.append(adjs)\n",
    "        verbList.append(verbs)\n",
    "        adverbList.append(adverbs)\n",
    "\n",
    "    nounSyn = pd.DataFrame()\n",
    "    adjSyn = pd.DataFrame()\n",
    "    verbSyn = pd.DataFrame()\n",
    "    avSyn = pd.DataFrame()\n",
    "\n",
    "    nounSyn['word'] = unique_\n",
    "    adjSyn['word'] = unique_\n",
    "    verbSyn['word'] = unique_\n",
    "    avSyn['word'] = unique_\n",
    "    ############################### Noun ####################################\n",
    "    l1=[]\n",
    "    for i in range(len(nounList)):\n",
    "        try:\n",
    "            l1.append(nounList[i][0])\n",
    "        except:\n",
    "            l1.append('N/A')  \n",
    "    nounSyn['1st_synonym']= pd.Series(l1)\n",
    "\n",
    "    l2=[]\n",
    "    for i in range(len(nounList)):\n",
    "        try:\n",
    "            l2.append(nounList[i][1])\n",
    "        except:\n",
    "            l2.append('N/A')\n",
    "    nounSyn['2nd_synonym']= pd.Series(l2)\n",
    "\n",
    "    l3=[]\n",
    "    for i in range(len(nounList)):\n",
    "        try:\n",
    "            l3.append(nounList[i][2])\n",
    "        except:\n",
    "            l3.append('N/A')\n",
    "    nounSyn['3rd_synonym']= pd.Series(l3)\n",
    "\n",
    "\n",
    "    ############################### Adjective ####################################\n",
    "    l1=[]\n",
    "    for i in range(len(adjList)):\n",
    "        try:\n",
    "            l1.append(adjList[i][0])\n",
    "        except:\n",
    "            l1.append('N/A')  \n",
    "    adjSyn['1st_synonym']= pd.Series(l1)\n",
    "\n",
    "    l2=[]\n",
    "    for i in range(len(adjList)):\n",
    "        try:\n",
    "            l2.append(adjList[i][1])\n",
    "        except:\n",
    "            l2.append('N/A')\n",
    "    adjSyn['2nd_synonym']= pd.Series(l2)\n",
    "\n",
    "    l3=[]\n",
    "    for i in range(len(adjList)):\n",
    "        try:\n",
    "            l3.append(adjList[i][2])\n",
    "        except:\n",
    "            l3.append('N/A')\n",
    "    adjSyn['3rd_synonym']= pd.Series(l3)\n",
    "\n",
    "\n",
    "    ############################### Verb ####################################\n",
    "    l1=[]\n",
    "    for i in range(len(verbList)):\n",
    "        try:\n",
    "            l1.append(verbList[i][0])\n",
    "        except:\n",
    "            l1.append('N/A')  \n",
    "    verbSyn['1st_synonym']= pd.Series(l1)\n",
    "\n",
    "    l2=[]\n",
    "    for i in range(len(verbList)):\n",
    "        try:\n",
    "            l2.append(verbList[i][1])\n",
    "        except:\n",
    "            l2.append('N/A')\n",
    "    verbSyn['2nd_synonym']= pd.Series(l2)\n",
    "\n",
    "    l3=[]\n",
    "    for i in range(len(verbList)):\n",
    "        try:\n",
    "            l3.append(verbList[i][2])\n",
    "        except:\n",
    "            l3.append('N/A')\n",
    "    verbSyn['3rd_synonym']= pd.Series(l3)\n",
    "\n",
    "\n",
    "    ############################### Adverb ####################################\n",
    "    l1=[]\n",
    "    for i in range(len(adverbList)):\n",
    "        try:\n",
    "            l1.append(adverbList[i][0])\n",
    "        except:\n",
    "            l1.append('N/A')  \n",
    "    avSyn['1st_synonym']= pd.Series(l1)\n",
    "\n",
    "    l2=[]\n",
    "    for i in range(len(adverbList)):\n",
    "        try:\n",
    "            l2.append(adverbList[i][1])\n",
    "        except:\n",
    "            l2.append('N/A')\n",
    "    avSyn['2nd_synonym']= pd.Series(l2)\n",
    "\n",
    "    l3=[]\n",
    "    for i in range(len(adverbList)):\n",
    "        try:\n",
    "            l3.append(adverbList[i][2])\n",
    "        except:\n",
    "            l3.append('N/A')\n",
    "    avSyn['3rd_synonym']= pd.Series(l3)\n",
    "\n",
    "   \n",
    "    return (nounSyn,adjSyn,verbSyn,avSyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDictionay (dictionary):\n",
    "    '''Function to clean the synynom dictionary \n",
    "    takes one argument :\n",
    "    dictionary - synynom dictionary'''\n",
    "    \n",
    "    # removing irrelevant words \n",
    "    dirty = ['one','two','three','four','five','six','seven','eight','nine','carbon','milliliters','liters','potassium',\n",
    "    'second','gastrointestinal','litre','oxygen','min','became','eye','full','elevated','radius','law','years','fall',\n",
    "    'bone','less','year']\n",
    "    dictionary['word'] = dictionary['word'].apply(lambda x : x if x not in dirty else '2')\n",
    "\n",
    "    # remove words of length of 2 ( of, in, to)\n",
    "    dictionary['word'] = dictionary['word'].apply(lambda x : x if len(x)>2 else '2')# when we replace it by a number the next line \n",
    "                                                                                    # will delete it automatically since it is a number \n",
    "    # remove digits from the synynom dictionary\n",
    "    dictionary = dictionary[~dictionary.word.str.contains(r'[0-9]')]\n",
    "    \n",
    "    # remove words that doesn't have synynoms\n",
    "    dictionary = dictionary[dictionary['1st_synonym']!='N/A']\n",
    "    \n",
    "    # correct the syntax of the word\n",
    "    dictionary['1st_synonym'] = dictionary['1st_synonym'].map(lambda x:str(x).replace('_',' '))\n",
    "    dictionary['2nd_synonym'] = dictionary['2nd_synonym'].map(lambda x:str(x).replace('_',' '))\n",
    "    dictionary['3rd_synonym'] = dictionary['3rd_synonym'].map(lambda x:str(x).replace('_',' '))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestSynynoms(qlist,nounSyn,adjSyn,verbSyn,avSyn):\n",
    "    ''' Function that takes a list of questions and returns the question with a new replaced synynom\n",
    "    takes one argument :\n",
    "    qlist - list of questions'''\n",
    "\n",
    "    # Dectionaries that we created it before from calssifySynynoms function\n",
    "#     nounSyn=pd.read_excel('nounsDictionary3.xlsx')\n",
    "#     adjSyn=pd.read_excel('adjectiveDictionary3.xlsx')\n",
    "#     verbSyn=pd.read_excel('verbDictionary3.xlsx')\n",
    "#     avSyn=pd.read_excel('adverbDictionary3.xlsx')\n",
    "    lstFound = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n",
    "    \n",
    "    oun = list(nounSyn['word'].unique())\n",
    "    oun.extend(list(adjSyn['word'].unique()))\n",
    "    oun.extend(list(verbSyn['word'].unique()))\n",
    "    oun.extend(list(avSyn['word'].unique()))\n",
    "    o = []\n",
    "    # traverse for all elements\n",
    "    for x in oun:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in o:\n",
    "            o.append(x)\n",
    "            \n",
    "    for q in qlist:\n",
    "        q1 = tokenizer.tokenize(q.lower())\n",
    "        # traverse for all words in q1\n",
    "        for i in q1:\n",
    "                if i in o:\n",
    "                    lstFound.append(i)\n",
    "    \n",
    "    numToReplace = randint(1, len(lstFound))\n",
    "    lstToReplace = random.sample(lstFound, numToReplace)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n",
    "    newq=''\n",
    "    new_qlist=[]\n",
    "    q_with_capital=''\n",
    "    for q in qlist:\n",
    "#         q2 = tokenizer.tokenize(q)\n",
    "#         for word in q2:\n",
    "#             # if it is true it will not convert it to lowercase\n",
    "#             if (word.isupper() == True)&(word != 'A'):\n",
    "#                 q_with_capital=q_with_capital+word\n",
    "#                 q_with_capital=q_with_capital+' '\n",
    "#             else:\n",
    "#                 q_with_capital=q_with_capital+word.lower()\n",
    "#                 q_with_capital=q_with_capital+' '\n",
    "\n",
    "        q1 = tokenizer.tokenize(q.lower())\n",
    "        for i in q1:\n",
    "            if i not in o or i not in lstToReplace:\n",
    "                newq=newq+i\n",
    "                newq=newq+' '\n",
    "            \n",
    "            elif i in o and i in lstToReplace:\n",
    "                text = nltk.word_tokenize(q)\n",
    "                result = nltk.pos_tag(q1)\n",
    "                result = [e for e in result if e[0].lower() == i]\n",
    "                type_= result[0][1]\n",
    "                \n",
    "                if type_ in ['NN','NNS','NNP','NN','NNPS']:\n",
    "                    try:\n",
    "                        #####\n",
    "                        all_syn= list(nounSyn.loc[nounSyn['word']==i].iloc[0])\n",
    "                        liss= [r for r in all_syn if r !='N/A' and r!=i]\n",
    "                        sample(liss,1)\n",
    "                        #####\n",
    "                        newq=newq+str(sample(liss,1)[0])\n",
    "                        newq=newq+' '\n",
    "                    except:\n",
    "                        newq=newq+i\n",
    "                        newq=newq+' '\n",
    "\n",
    "\n",
    "                elif type_ in ['JJ','JJR','JJS']:\n",
    "                        try:\n",
    "                             #####\n",
    "                            all_syn= list(adjSyn.loc[adjSyn['word']==i].iloc[0])\n",
    "                            liss= [r for r in all_syn if r !='N/A' and r!=i]\n",
    "                            sample(liss,1)\n",
    "                            #####\n",
    "                            newq=newq+str(sample(liss,1)[0])\n",
    "                            newq=newq+' '\n",
    "                        except:\n",
    "                            newq=newq+i\n",
    "                            newq=newq+' '\n",
    "\n",
    "                elif type_ in ['VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                    try:\n",
    "                        #####\n",
    "                        all_syn= list(verbSyn.loc[verbSyn['word']==i].iloc[0])\n",
    "                        liss= [r for r in all_syn if r !='N/A' and r!=i]\n",
    "                        sample(liss,1)\n",
    "                        #####\n",
    "                        newq=newq+str(sample(liss,1)[0])\n",
    "                        newq=newq+' '\n",
    "                    except:\n",
    "                        newq=newq+i\n",
    "                        newq=newq+' '\n",
    "                    \n",
    "\n",
    "                elif type_ in ['RB','RBR','RBS']:\n",
    "                    try:\n",
    "                        #####\n",
    "                        all_syn= list(avSyn.loc[avSyn['word']==i].iloc[0])\n",
    "                        liss= [r for r in all_syn if r !='N/A' and r!=i]\n",
    "                        sample(liss,1)\n",
    "                        #####\n",
    "                        newq=newq+str(sample(liss,1)[0])\n",
    "                        newq=newq+' '\n",
    "                    except:\n",
    "                        newq=newq+i\n",
    "                        newq=newq+' '\n",
    "                    \n",
    "                else:\n",
    "                    newq=newq+i\n",
    "                    newq=newq+' '\n",
    "\n",
    "        new_qlist.append(newq)\n",
    "        newq=''\n",
    "    return new_qlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestVariable (q):\n",
    "    ''' Function that takes a question and returns the question with a new replaced variable\n",
    "    takes one argument :\n",
    "    q - question'''\n",
    "    \n",
    "    sentences = list(pd.read_excel('sent_var.xlsx')['sentences'])\n",
    "    variables = pd.read_excel('sent_var.xlsx').drop('Unnamed: 0', axis = 1)\n",
    "    s =''\n",
    "    \n",
    "    for i in range(0,len(sentences)):\n",
    "        if sentences[i] in q:\n",
    "            replacement = variables[variables['sentences'] == sentences[i]]['variables'].iloc[0]\n",
    "            q = q.replace(sentences[i], replacement)\n",
    "            break\n",
    "    \n",
    "    # lists for ages \n",
    "    age1 = [1,2,3,4,5]\n",
    "    age2 = [6,7,8,9,10,11,12,13]\n",
    "    age3 = [14,15,16,17,18,19]\n",
    "    age4 = [x for x in range (20,30)]\n",
    "    age5 = [x for x in range (30,40)]\n",
    "    age6 = [x for x in range (40,50)]\n",
    "    age7 = [x for x in range (50,65)]\n",
    "    age8 = [x for x in range (65,120)]\n",
    "    newAge = 0\n",
    "    \n",
    "    # replacing ages \n",
    "    if 'year-old' in q:\n",
    "        try:\n",
    "            age = int(re.findall(r'\\d+', q.split('year-old')[0])[0])\n",
    "        except:\n",
    "            return q\n",
    "            \n",
    "        if age in age1:\n",
    "            newAge = sample(age1,1)\n",
    "        elif age in age2:\n",
    "            newAge = sample(age2,1)\n",
    "        elif age in age3:\n",
    "            newAge = sample(age3,1)\n",
    "        elif age in age4:\n",
    "            newAge = sample(age4,1)\n",
    "        elif age in age5:\n",
    "            newAge = sample(age5,1)\n",
    "        elif age in age6:\n",
    "            newAge = sample(age6,1)\n",
    "        elif age in age7:\n",
    "            newAge = sample(age7,1)\n",
    "        elif age in age8:\n",
    "            newAge = sample(age8,1)\n",
    "        q = q.replace(str(age),str(newAge[0]))\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender function will specify the gender mentioned in a specific question\n",
    "\n",
    "def gender(question):\n",
    "    \"\"\" Specify the gender of a specific question\n",
    "    Take one argument \n",
    "    question- one question \n",
    "    \"\"\"\n",
    "    all_genders= ['she','her','hers','he','him','his']\n",
    "    # list of female pronouns\n",
    "    female_pronouns= ['she','her','hers']\n",
    "    # list of male pronouns\n",
    "    male_pronouns= ['he','him','his']\n",
    "    # list of possible synonymous of male \n",
    "    male = ['male','boy','youngman','man']\n",
    "    # list of possible synonymous of female\n",
    "    female = ['female','girl','lady','woman']\n",
    "    # list of possible words of unknown gender\n",
    "    unknown= ['patient','someone']\n",
    "    # list of possible words of plural\n",
    "    plural= ['patients','men','women']\n",
    "    \n",
    "\n",
    "    # tokenizer splits tokens \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    q = tokenizer.tokenize(question)\n",
    "    \n",
    "    # traverse for all words in q\n",
    "    for i in q:\n",
    "        \n",
    "        # traverse for all words in male list\n",
    "        if i in male:\n",
    "            for w in q:\n",
    "                if w in female:\n",
    "                    # in case there is male and female in the question\n",
    "                    return ('plural')\n",
    "            return('male')\n",
    "        \n",
    "        # traverse for all words in female list\n",
    "        if i in female:\n",
    "            for u in q:\n",
    "                if u in male:\n",
    "                    # in case there is male and female in the question\n",
    "                    return ('plural')      \n",
    "            return('female')\n",
    "        \n",
    "        if i in unknown:\n",
    "            # if the first word is in unknown list it will checks the next word if it is in female_pronouns list or male_pronouns list \n",
    "            for e in q:\n",
    "                if e in all_genders:\n",
    "                    if e in female_pronouns:\n",
    "                        return('female')\n",
    "                    elif e in male_pronouns:\n",
    "                        return ('male')\n",
    "        if i in plural:\n",
    "            return('plural')\n",
    "                \n",
    "    return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar checker function will do the folowing : \n",
    "# 1. Editing gender pronouns\n",
    "# 2. Editing identifiers\n",
    "# 3. Editing letter case\n",
    "# 4. Control spacing\n",
    "# 5. Correcting spelling and grammar\n",
    "  \n",
    "def grammar_checker(q):\n",
    "    \"\"\" Editing gender pronouns, identifiers and letter case. Control spacing and correcting spelling and grammar mistakes\n",
    "   \n",
    "    Take one argument \n",
    "    q- list of questions\n",
    "    \"\"\"\n",
    "    # list of subject pronouns\n",
    "    l1= ['I','you','he', 'she', 'it','we','they']\n",
    "    # list of object pronouns\n",
    "    l2= ['me','you','him','her','it','us','them']\n",
    "    # list of possessive adjectives \n",
    "    l3= ['my','your','his','her','its','our','their']\n",
    "    # list of possessive pronouns\n",
    "    l4= ['mine','yours','his','hers','its','ours','theirs']\n",
    "    \n",
    "    # assign GingerIt() to parser\n",
    "    parser = GingerIt()\n",
    "    \n",
    "    # create empty list \n",
    "    list_of_questions=[]\n",
    "    \n",
    "    # for loop to enter each question in the list\n",
    "    for index in range(len(q)):\n",
    "        \n",
    "        # change the type of question to string\n",
    "        question=str(q[index])\n",
    "        \n",
    "        # call gender function to know the gender mentioned in the question\n",
    "        gender_=gender(question)\n",
    "        \n",
    "        # splits tokens by white space \n",
    "        tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n",
    "        q1= tokenizer.tokenize(question)\n",
    "        \n",
    "        # if gender = female, change the pronouns to: she, her, hers \n",
    "        if gender_ == 'female':\n",
    "            for i in q1:\n",
    "                if i in l1:\n",
    "                    question=question.replace(i,'she')\n",
    "                elif i in l2:\n",
    "                    question=question.replace(i,'her')\n",
    "                elif i in l3:\n",
    "                    question=question.replace(i,'her')\n",
    "                elif i in l4:\n",
    "                    question=question.replace(i,'hers')\n",
    "                    \n",
    "        # if gender = male, change the pronouns to: he, him, his\n",
    "        elif gender_ == 'male': \n",
    "            for i in q1:\n",
    "                if i in l1:\n",
    "                    question=question.replace(i,'he')\n",
    "                elif i in l2:\n",
    "                    question=question.replace(i,'him')\n",
    "                elif i in l3:\n",
    "                    question=question.replace(i,'his')\n",
    "                elif i in l4:\n",
    "                    question=question.replace(i,'his')\n",
    "                    \n",
    "         # if it is plural, change the pronouns to: they, them, their, theirs\n",
    "        elif gender_ == 'plural': \n",
    "            for i in q1:\n",
    "                if i in l1:\n",
    "                    question=question.replace(i,'they')\n",
    "                elif i in l2:\n",
    "                    question=question.replace(i,'them')\n",
    "                elif i in l3:\n",
    "                    question=question.replace(i,'their')\n",
    "                elif i in l4:\n",
    "                    question=question.replace(i,'theirs')\n",
    "        try: \n",
    "            # change first character after dot to uppercase and apply the GingerIt() on the question               \n",
    "            capitalize=\". \".join(i.capitalize() for i in parser.parse(question)['result'].split(\". \"))\n",
    "            # add question to list_of_questions list    \n",
    "            list_of_questions.append(capitalize)\n",
    "        except:\n",
    "            # add question to list_of_questions list \n",
    "            try:\n",
    "                list_of_questions.append(parser.parse(question)['result'])\n",
    "            except:\n",
    "                list_of_questions.append(question)\n",
    "    # return the new list \n",
    "    return (list_of_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
